{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " 預處理步驟：\n",
    " 1. 讀取 csv 檔案中的 item names -> 取得所有產品的 item names。\n",
    " 2. 因在本機運算(使用cpu)，使用少部分資料進行模型訓練測試。\n",
    " 3. 準備訓練、測試資料集 -> 因我們的資料為 unsupervised，故以jieba+預處理的結果作為斷詞之 ground_truth。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItems(file_name, item_col):\n",
    "    df = pd.read_csv(file_name)\n",
    "    return df[item_col].tolist()\n",
    "    \n",
    "def filterItem(item_name, stopwords, all_items):\n",
    "    item_idx = [idx for idx, name in enumerate(all_items) if item_name in name.lower()]\n",
    "    item_list = [all_item_names[idx].lower() for idx in item_idx]\n",
    "    \n",
    "    filter_item_name = []\n",
    "    for item in item_list:\n",
    "        item_name = []\n",
    "        item = re.sub(r'[^\\w]', ' ', item) # remove symbols\n",
    "        item = re.sub(r\"\\s+\", \" \", item)  # remove 一個以上的空白字符\n",
    "        split_item = item.strip().split(' ')\n",
    "        \n",
    "        for word in split_item:\n",
    "            if word in stopwords:\n",
    "                continue\n",
    "            else:\n",
    "                item_name.append(word)\n",
    "        filter_item_name.append(\" \".join(item_name))\n",
    "    \n",
    "    return filter_item_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the filter items:  10114\n",
      "\n",
      "['apple iphone 11 128gb 6 1吋 白 黑 紅 黃 紫 綠 神腦生活', 'apple iphone 11 pro max 256gb 6 5吋 灰 銀 金 綠 神腦生活', 'apple iphone xs 256gb 下殺8折', 'apple iphone 11 64gb 6 1吋 紅 白 黑 黃 綠 紫 神腦生活', 'apple iphone 11 pro max 64gb 6 5吋 灰 銀 金 綠 神腦生活']\n"
     ]
    }
   ],
   "source": [
    "#1. get items\n",
    "all_item_names = getItems('mall_all_item.csv', 'item_name')\n",
    "\n",
    "# 2. filer items\n",
    "item_name = 'iphone'\n",
    "stopwords = []\n",
    "filter_item_list = filterItem(item_name, stopwords, all_item_names)\n",
    "print(\"Length of the filter items: \", len(filter_item_list))\n",
    "print()\n",
    "print(filter_item_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.the function that tag the word\n",
    "def words_to_tags(sent):\n",
    "    tags = []\n",
    "    for word in sent:\n",
    "        if len(word) == 1:\n",
    "            tags.append('S')\n",
    "        else:\n",
    "            for i in range(len(word)):\n",
    "                if i == 0:\n",
    "                    tags.append('L')\n",
    "                elif i == len(word) - 1:\n",
    "                    tags.append('R')\n",
    "                else:\n",
    "                    tags.append('M')                    \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\SAM~1.HSI\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.261 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 3. the function for preparing the train, test dataset\n",
    "def prepareDataset(item_list):\n",
    "    X = []\n",
    "    y = []\n",
    "    raw = []\n",
    "    \n",
    "    word_to_ix = {}\n",
    "    word_to_ix['UNK'] = 0\n",
    "    \n",
    "    for item in item_list:\n",
    "        split_item_sent = list(jieba.cut(item))\n",
    "        raw.append(split_item_sent)\n",
    "        \n",
    "        sent_words = list(\"\".join(split_item_sent))\n",
    "        for word in sent_words:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "        \n",
    "        X.append(sent_words)\n",
    "        y.append(words_to_tags(split_item_sent))\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "                                            test_size=0.2, random_state=42)\n",
    "    \n",
    "    raw_train, raw_test = train_test_split(raw, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, raw_train, raw_test, word_to_ix\n",
    "\n",
    "X_train, X_test, y_train, y_test, raw_train, raw_test, word_to_ix = prepareDataset(filter_item_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a CRF model for word segmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " 使用 CRF model 去建構 word segmentation 的 feature function\n",
    " 有許多不同的 package 支援 CRF model 運算，而在此使用的是 sklearn_crfsuite。\n",
    " \n",
    " CRF feature function 捕捉之資訊：\n",
    " 1. 當前字詞前3個字，與後4個字。\n",
    " 2. 此單字是否為第一個字 or 最後一個字。\n",
    " 3. bigram, trigram 資訊。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers, metrics\n",
    "\n",
    "def extract_char_features(sent, position):\n",
    "    char_features = {}\n",
    "    for i in range(-3, 4):\n",
    "        if len(sent) > position + i >= 0:\n",
    "            char_features['char_at_%d' % i] = sent[position + i]\n",
    "    \n",
    "    if position == 0:\n",
    "        char_features['First_word']: True\n",
    "        char_features['Last_word'] : False\n",
    "        pass\n",
    "    \n",
    "    elif position == 1:\n",
    "        bigram = sent[position-1] + sent[position]\n",
    "        \n",
    "        char_features['bigram'] = bigram\n",
    "        char_features['First_word']: False\n",
    "        char_features['Last_word'] : False\n",
    "    \n",
    "    elif position == len(sent)-1:\n",
    "        bigram = sent[position-1] + sent[position]\n",
    "        trigram = sent[position-2] + sent[position-1] + sent[position]\n",
    "        char_features['bigram'] = bigram\n",
    "        char_features['trigram'] = trigram\n",
    "        char_features['First_word']: False\n",
    "        char_features['Last_word'] : True\n",
    "        \n",
    "    else:\n",
    "        bigram = sent[position-1] + sent[position]\n",
    "        trigram = sent[position-2] + sent[position-1] + sent[position]\n",
    "        \n",
    "        char_features['bigram'] = bigram\n",
    "        char_features['trigram'] = trigram\n",
    "        char_features['First_word']: False\n",
    "        char_features['Last_word'] : False\n",
    "    \n",
    "    return char_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sent_features(sent):\n",
    "    sent_features = []\n",
    "    \n",
    "    for i in range(len(sent)):\n",
    "        sent_features.append(extract_char_features(sent, i))\n",
    "        \n",
    "    return sent_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the feature of training set to fit the CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714335a51d5949c790aef47ef6c10d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8091), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crf_tagger = sklearn_crfsuite.CRF(algorithm='lbfgs',\n",
    "                                  min_freq=20,\n",
    "                                  max_iterations=300,\n",
    "                                  c1=10,\n",
    "                                  c2=0.1,\n",
    "                                  verbose=True)\n",
    "\n",
    "feature_X = []\n",
    "for sent in tqdm_notebook(X_train):\n",
    "    feature_X.append(extract_sent_features(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|█████████████████████████████████████████| 8091/8091 [00:04<00:00, 1737.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 20.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 11003\n",
      "Seconds required: 1.547\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 10.000000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 300\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.50  loss=438682.15 active=9570  feature_norm=1.00\n",
      "Iter 2   time=0.25  loss=219682.90 active=9470  feature_norm=7.34\n",
      "Iter 3   time=0.26  loss=138347.61 active=9012  feature_norm=8.75\n",
      "Iter 4   time=0.26  loss=109300.22 active=9233  feature_norm=9.26\n",
      "Iter 5   time=0.26  loss=92615.43 active=9304  feature_norm=9.95\n",
      "Iter 6   time=0.23  loss=83522.89 active=8977  feature_norm=10.73\n",
      "Iter 7   time=0.20  loss=74198.92 active=8589  feature_norm=11.95\n",
      "Iter 8   time=0.21  loss=60168.15 active=7797  feature_norm=14.17\n",
      "Iter 9   time=0.22  loss=58336.94 active=7350  feature_norm=15.91\n",
      "Iter 10  time=0.25  loss=49526.41 active=7284  feature_norm=17.41\n",
      "Iter 11  time=0.24  loss=47687.44 active=7060  feature_norm=18.62\n",
      "Iter 12  time=0.27  loss=44513.70 active=6992  feature_norm=19.79\n",
      "Iter 13  time=0.25  loss=43292.62 active=6828  feature_norm=20.92\n",
      "Iter 14  time=0.24  loss=41247.95 active=6678  feature_norm=21.79\n",
      "Iter 15  time=0.23  loss=39996.98 active=6533  feature_norm=22.54\n",
      "Iter 16  time=0.23  loss=38567.57 active=6381  feature_norm=23.49\n",
      "Iter 17  time=0.26  loss=37438.47 active=6235  feature_norm=24.30\n",
      "Iter 18  time=0.29  loss=36437.41 active=6103  feature_norm=25.26\n",
      "Iter 19  time=0.27  loss=35575.90 active=5998  feature_norm=26.03\n",
      "Iter 20  time=0.28  loss=34860.77 active=5889  feature_norm=26.84\n",
      "Iter 21  time=0.30  loss=34193.54 active=5769  feature_norm=27.55\n",
      "Iter 22  time=0.23  loss=33743.31 active=5664  feature_norm=28.31\n",
      "Iter 23  time=0.29  loss=33154.60 active=5525  feature_norm=28.95\n",
      "Iter 24  time=0.28  loss=32730.76 active=5415  feature_norm=29.62\n",
      "Iter 25  time=0.26  loss=32361.55 active=5299  feature_norm=30.14\n",
      "Iter 26  time=0.24  loss=32033.41 active=5193  feature_norm=30.67\n",
      "Iter 27  time=0.27  loss=31781.32 active=5092  feature_norm=31.15\n",
      "Iter 28  time=0.25  loss=31472.70 active=4983  feature_norm=31.61\n",
      "Iter 29  time=0.28  loss=31217.16 active=4813  feature_norm=32.11\n",
      "Iter 30  time=0.28  loss=30923.68 active=4684  feature_norm=32.60\n",
      "Iter 31  time=0.25  loss=30670.07 active=4564  feature_norm=33.08\n",
      "Iter 32  time=0.22  loss=30394.17 active=4415  feature_norm=33.46\n",
      "Iter 33  time=0.25  loss=30173.97 active=4282  feature_norm=33.89\n",
      "Iter 34  time=0.22  loss=29945.88 active=4124  feature_norm=34.26\n",
      "Iter 35  time=0.27  loss=29735.20 active=4004  feature_norm=34.60\n",
      "Iter 36  time=0.27  loss=29570.62 active=3863  feature_norm=34.95\n",
      "Iter 37  time=0.24  loss=29379.40 active=3762  feature_norm=35.25\n",
      "Iter 38  time=0.24  loss=29220.65 active=3644  feature_norm=35.52\n",
      "Iter 39  time=0.24  loss=29066.09 active=3540  feature_norm=35.81\n",
      "Iter 40  time=0.22  loss=28903.38 active=3413  feature_norm=35.98\n",
      "Iter 41  time=0.22  loss=28782.93 active=3264  feature_norm=36.19\n",
      "Iter 42  time=0.23  loss=28634.00 active=3143  feature_norm=36.40\n",
      "Iter 43  time=0.24  loss=28524.95 active=3048  feature_norm=36.62\n",
      "Iter 44  time=0.23  loss=28422.48 active=2942  feature_norm=36.79\n",
      "Iter 45  time=0.25  loss=28344.58 active=2865  feature_norm=36.86\n",
      "Iter 46  time=0.26  loss=28267.11 active=2787  feature_norm=36.97\n",
      "Iter 47  time=0.27  loss=28201.62 active=2710  feature_norm=37.04\n",
      "Iter 48  time=0.23  loss=28123.52 active=2657  feature_norm=37.16\n",
      "Iter 49  time=0.22  loss=28067.33 active=2590  feature_norm=37.23\n",
      "Iter 50  time=0.24  loss=28003.07 active=2525  feature_norm=37.30\n",
      "Iter 51  time=0.27  loss=27959.51 active=2468  feature_norm=37.31\n",
      "Iter 52  time=0.25  loss=27911.95 active=2405  feature_norm=37.36\n",
      "Iter 53  time=0.22  loss=27869.07 active=2347  feature_norm=37.39\n",
      "Iter 54  time=0.23  loss=27827.05 active=2295  feature_norm=37.44\n",
      "Iter 55  time=0.25  loss=27790.61 active=2267  feature_norm=37.54\n",
      "Iter 56  time=0.25  loss=27752.96 active=2222  feature_norm=37.65\n",
      "Iter 57  time=0.25  loss=27721.98 active=2193  feature_norm=37.76\n",
      "Iter 58  time=0.25  loss=27689.38 active=2164  feature_norm=37.88\n",
      "Iter 59  time=0.22  loss=27665.78 active=2144  feature_norm=37.98\n",
      "Iter 60  time=0.22  loss=27635.73 active=2118  feature_norm=38.08\n",
      "Iter 61  time=0.24  loss=27612.31 active=2098  feature_norm=38.19\n",
      "Iter 62  time=0.24  loss=27586.99 active=2076  feature_norm=38.32\n",
      "Iter 63  time=0.29  loss=27559.71 active=2061  feature_norm=38.43\n",
      "Iter 64  time=0.27  loss=27537.66 active=2036  feature_norm=38.57\n",
      "Iter 65  time=0.26  loss=27513.16 active=2013  feature_norm=38.68\n",
      "Iter 66  time=0.23  loss=27495.64 active=1996  feature_norm=38.81\n",
      "Iter 67  time=0.28  loss=27470.90 active=1968  feature_norm=38.93\n",
      "Iter 68  time=0.29  loss=27457.30 active=1951  feature_norm=39.07\n",
      "Iter 69  time=0.28  loss=27428.63 active=1931  feature_norm=39.19\n",
      "Iter 70  time=0.27  loss=27419.44 active=1918  feature_norm=39.34\n",
      "Iter 71  time=0.24  loss=27391.64 active=1909  feature_norm=39.44\n",
      "Iter 72  time=0.22  loss=27385.60 active=1897  feature_norm=39.58\n",
      "Iter 73  time=0.26  loss=27361.67 active=1891  feature_norm=39.70\n",
      "Iter 74  time=0.23  loss=27352.78 active=1883  feature_norm=39.83\n",
      "Iter 75  time=0.25  loss=27332.97 active=1873  feature_norm=39.94\n",
      "Iter 76  time=0.23  loss=27325.01 active=1862  feature_norm=40.06\n",
      "Iter 77  time=0.27  loss=27307.93 active=1846  feature_norm=40.15\n",
      "Iter 78  time=0.25  loss=27298.94 active=1836  feature_norm=40.27\n",
      "Iter 79  time=0.26  loss=27283.89 active=1832  feature_norm=40.35\n",
      "Iter 80  time=0.27  loss=27277.85 active=1826  feature_norm=40.46\n",
      "Iter 81  time=0.22  loss=27261.55 active=1819  feature_norm=40.56\n",
      "Iter 82  time=0.23  loss=27254.59 active=1801  feature_norm=40.66\n",
      "Iter 83  time=0.22  loss=27239.58 active=1790  feature_norm=40.74\n",
      "Iter 84  time=0.24  loss=27233.22 active=1779  feature_norm=40.83\n",
      "Iter 85  time=0.22  loss=27218.96 active=1769  feature_norm=40.90\n",
      "Iter 86  time=0.24  loss=27214.34 active=1758  feature_norm=40.99\n",
      "Iter 87  time=0.22  loss=27200.14 active=1748  feature_norm=41.07\n",
      "Iter 88  time=0.23  loss=27196.40 active=1740  feature_norm=41.16\n",
      "Iter 89  time=0.23  loss=27183.51 active=1725  feature_norm=41.22\n",
      "Iter 90  time=0.26  loss=27180.15 active=1724  feature_norm=41.30\n",
      "Iter 91  time=0.26  loss=27168.47 active=1715  feature_norm=41.35\n",
      "Iter 92  time=0.21  loss=27165.25 active=1703  feature_norm=41.42\n",
      "Iter 93  time=0.24  loss=27153.74 active=1689  feature_norm=41.48\n",
      "Iter 94  time=0.25  loss=27150.85 active=1679  feature_norm=41.56\n",
      "Iter 95  time=0.24  loss=27138.69 active=1673  feature_norm=41.61\n",
      "Iter 96  time=0.22  loss=27134.52 active=1664  feature_norm=41.68\n",
      "Iter 97  time=0.21  loss=27124.98 active=1652  feature_norm=41.73\n",
      "Iter 98  time=0.26  loss=27121.29 active=1651  feature_norm=41.80\n",
      "Iter 99  time=0.26  loss=27112.72 active=1647  feature_norm=41.84\n",
      "Iter 100 time=0.24  loss=27108.72 active=1640  feature_norm=41.91\n",
      "Iter 101 time=0.25  loss=27100.09 active=1632  feature_norm=41.97\n",
      "Iter 102 time=0.25  loss=27096.16 active=1627  feature_norm=42.03\n",
      "Iter 103 time=0.23  loss=27088.28 active=1619  feature_norm=42.08\n",
      "Iter 104 time=0.22  loss=27084.70 active=1614  feature_norm=42.14\n",
      "Iter 105 time=0.21  loss=27077.54 active=1608  feature_norm=42.18\n",
      "Iter 106 time=0.25  loss=27074.83 active=1605  feature_norm=42.24\n",
      "Iter 107 time=0.24  loss=27067.27 active=1594  feature_norm=42.29\n",
      "Iter 108 time=0.24  loss=27064.56 active=1588  feature_norm=42.35\n",
      "Iter 109 time=0.24  loss=27056.60 active=1580  feature_norm=42.40\n",
      "Iter 110 time=0.24  loss=27054.50 active=1577  feature_norm=42.46\n",
      "Iter 111 time=0.22  loss=27047.54 active=1571  feature_norm=42.50\n",
      "Iter 112 time=0.24  loss=27045.79 active=1568  feature_norm=42.56\n",
      "Iter 113 time=0.24  loss=27039.37 active=1566  feature_norm=42.61\n",
      "Iter 114 time=0.22  loss=27037.15 active=1558  feature_norm=42.67\n",
      "Iter 115 time=0.21  loss=27031.65 active=1553  feature_norm=42.72\n",
      "Iter 116 time=0.25  loss=27029.36 active=1548  feature_norm=42.77\n",
      "Iter 117 time=0.23  loss=27024.63 active=1531  feature_norm=42.81\n",
      "Iter 118 time=0.25  loss=27022.10 active=1530  feature_norm=42.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 119 time=0.24  loss=27018.58 active=1526  feature_norm=42.89\n",
      "Iter 120 time=0.22  loss=27016.37 active=1519  feature_norm=42.94\n",
      "Iter 121 time=0.22  loss=27012.39 active=1515  feature_norm=42.98\n",
      "Iter 122 time=0.24  loss=27010.51 active=1512  feature_norm=43.03\n",
      "Iter 123 time=0.26  loss=27006.93 active=1511  feature_norm=43.07\n",
      "Iter 124 time=0.23  loss=27004.94 active=1509  feature_norm=43.11\n",
      "Iter 125 time=0.21  loss=27002.06 active=1510  feature_norm=43.14\n",
      "Iter 126 time=0.22  loss=26999.65 active=1510  feature_norm=43.18\n",
      "Iter 127 time=0.22  loss=26997.28 active=1508  feature_norm=43.21\n",
      "Iter 128 time=0.23  loss=26994.64 active=1502  feature_norm=43.26\n",
      "Iter 129 time=0.25  loss=26992.21 active=1492  feature_norm=43.29\n",
      "Iter 130 time=0.24  loss=26989.81 active=1490  feature_norm=43.34\n",
      "Iter 131 time=0.26  loss=26987.18 active=1490  feature_norm=43.37\n",
      "Iter 132 time=0.23  loss=26985.29 active=1483  feature_norm=43.42\n",
      "Iter 133 time=0.20  loss=26982.83 active=1481  feature_norm=43.45\n",
      "Iter 134 time=0.23  loss=26980.96 active=1478  feature_norm=43.50\n",
      "Iter 135 time=0.22  loss=26978.52 active=1474  feature_norm=43.52\n",
      "Iter 136 time=0.24  loss=26977.00 active=1477  feature_norm=43.57\n",
      "Iter 137 time=0.21  loss=26974.69 active=1475  feature_norm=43.60\n",
      "Iter 138 time=0.22  loss=26973.48 active=1470  feature_norm=43.64\n",
      "Iter 139 time=0.23  loss=26971.04 active=1470  feature_norm=43.67\n",
      "Iter 140 time=0.23  loss=26969.99 active=1462  feature_norm=43.70\n",
      "Iter 141 time=0.22  loss=26968.21 active=1457  feature_norm=43.72\n",
      "Iter 142 time=0.24  loss=26967.10 active=1455  feature_norm=43.75\n",
      "Iter 143 time=0.25  loss=26965.48 active=1449  feature_norm=43.77\n",
      "Iter 144 time=0.25  loss=26963.95 active=1446  feature_norm=43.80\n",
      "Iter 145 time=0.24  loss=26962.68 active=1442  feature_norm=43.83\n",
      "Iter 146 time=0.24  loss=26961.01 active=1439  feature_norm=43.86\n",
      "Iter 147 time=0.22  loss=26959.87 active=1439  feature_norm=43.88\n",
      "Iter 148 time=0.24  loss=26958.24 active=1438  feature_norm=43.91\n",
      "Iter 149 time=0.23  loss=26957.01 active=1436  feature_norm=43.93\n",
      "Iter 150 time=0.24  loss=26955.90 active=1434  feature_norm=43.96\n",
      "Iter 151 time=0.25  loss=26954.43 active=1426  feature_norm=43.98\n",
      "Iter 152 time=0.24  loss=26953.50 active=1423  feature_norm=44.01\n",
      "Iter 153 time=0.21  loss=26952.22 active=1423  feature_norm=44.02\n",
      "Iter 154 time=0.25  loss=26951.33 active=1419  feature_norm=44.05\n",
      "Iter 155 time=0.25  loss=26950.07 active=1417  feature_norm=44.07\n",
      "Iter 156 time=0.21  loss=26949.29 active=1412  feature_norm=44.10\n",
      "Iter 157 time=0.24  loss=26947.85 active=1411  feature_norm=44.11\n",
      "Iter 158 time=0.21  loss=26947.40 active=1404  feature_norm=44.14\n",
      "Iter 159 time=0.24  loss=26946.06 active=1399  feature_norm=44.15\n",
      "Iter 160 time=0.23  loss=26945.55 active=1397  feature_norm=44.17\n",
      "Iter 161 time=0.23  loss=26944.59 active=1395  feature_norm=44.18\n",
      "Iter 162 time=0.25  loss=26943.96 active=1389  feature_norm=44.21\n",
      "Iter 163 time=0.21  loss=26943.01 active=1388  feature_norm=44.22\n",
      "Iter 164 time=0.26  loss=26942.23 active=1385  feature_norm=44.24\n",
      "Iter 165 time=0.21  loss=26941.42 active=1384  feature_norm=44.25\n",
      "Iter 166 time=0.20  loss=26940.87 active=1382  feature_norm=44.27\n",
      "Iter 167 time=0.27  loss=26939.79 active=1386  feature_norm=44.27\n",
      "Iter 168 time=0.28  loss=26939.38 active=1387  feature_norm=44.29\n",
      "Iter 169 time=0.21  loss=26938.33 active=1386  feature_norm=44.30\n",
      "Iter 170 time=0.23  loss=26937.88 active=1384  feature_norm=44.32\n",
      "Iter 171 time=0.26  loss=26936.70 active=1382  feature_norm=44.33\n",
      "Iter 172 time=0.22  loss=26936.33 active=1381  feature_norm=44.35\n",
      "Iter 173 time=0.21  loss=26935.30 active=1376  feature_norm=44.36\n",
      "Iter 174 time=0.23  loss=26934.90 active=1375  feature_norm=44.38\n",
      "Iter 175 time=0.23  loss=26933.90 active=1371  feature_norm=44.39\n",
      "Iter 176 time=0.23  loss=26933.56 active=1369  feature_norm=44.41\n",
      "Iter 177 time=0.23  loss=26932.43 active=1366  feature_norm=44.42\n",
      "Iter 178 time=0.28  loss=26932.16 active=1365  feature_norm=44.44\n",
      "Iter 179 time=0.24  loss=26931.20 active=1366  feature_norm=44.46\n",
      "Iter 180 time=0.25  loss=26931.04 active=1363  feature_norm=44.49\n",
      "Iter 181 time=0.27  loss=26929.91 active=1361  feature_norm=44.50\n",
      "Iter 182 time=0.24  loss=26929.64 active=1359  feature_norm=44.51\n",
      "Iter 183 time=0.25  loss=26928.90 active=1357  feature_norm=44.53\n",
      "Iter 184 time=0.22  loss=26928.48 active=1357  feature_norm=44.54\n",
      "Iter 185 time=0.23  loss=26927.75 active=1357  feature_norm=44.55\n",
      "Iter 186 time=0.21  loss=26927.46 active=1354  feature_norm=44.57\n",
      "Iter 187 time=0.22  loss=26926.62 active=1350  feature_norm=44.58\n",
      "Iter 188 time=0.22  loss=26926.52 active=1348  feature_norm=44.60\n",
      "Iter 189 time=0.27  loss=26925.55 active=1345  feature_norm=44.61\n",
      "Iter 190 time=0.26  loss=26925.49 active=1347  feature_norm=44.62\n",
      "Iter 191 time=0.22  loss=26924.65 active=1349  feature_norm=44.63\n",
      "Iter 192 time=0.22  loss=26924.58 active=1348  feature_norm=44.65\n",
      "Iter 193 time=0.25  loss=26923.77 active=1348  feature_norm=44.66\n",
      "Iter 194 time=0.28  loss=26923.71 active=1349  feature_norm=44.67\n",
      "Iter 195 time=0.27  loss=26922.81 active=1350  feature_norm=44.69\n",
      "Iter 196 time=0.22  loss=26922.74 active=1353  feature_norm=44.70\n",
      "Iter 197 time=0.27  loss=26921.85 active=1353  feature_norm=44.72\n",
      "Iter 198 time=0.53  loss=26921.53 active=1353  feature_norm=44.72\n",
      "Iter 199 time=0.29  loss=26920.90 active=1353  feature_norm=44.74\n",
      "Iter 200 time=0.53  loss=26920.36 active=1353  feature_norm=44.75\n",
      "Iter 201 time=0.49  loss=26920.00 active=1347  feature_norm=44.76\n",
      "Iter 202 time=0.55  loss=26919.42 active=1345  feature_norm=44.77\n",
      "Iter 203 time=0.51  loss=26919.04 active=1342  feature_norm=44.79\n",
      "Iter 204 time=0.46  loss=26918.50 active=1343  feature_norm=44.80\n",
      "Iter 205 time=0.51  loss=26918.16 active=1343  feature_norm=44.81\n",
      "Iter 206 time=0.24  loss=26917.92 active=1341  feature_norm=44.82\n",
      "Iter 207 time=0.25  loss=26917.16 active=1336  feature_norm=44.83\n",
      "Iter 208 time=0.27  loss=26916.83 active=1334  feature_norm=44.85\n",
      "Iter 209 time=0.28  loss=26915.99 active=1332  feature_norm=44.86\n",
      "Iter 210 time=0.27  loss=26915.68 active=1334  feature_norm=44.86\n",
      "Iter 211 time=0.28  loss=26914.96 active=1334  feature_norm=44.87\n",
      "Iter 212 time=0.27  loss=26914.74 active=1333  feature_norm=44.88\n",
      "Iter 213 time=0.23  loss=26913.95 active=1331  feature_norm=44.89\n",
      "Iter 214 time=0.25  loss=26913.90 active=1330  feature_norm=44.89\n",
      "Iter 215 time=0.22  loss=26913.15 active=1327  feature_norm=44.90\n",
      "Iter 216 time=0.24  loss=26913.02 active=1327  feature_norm=44.90\n",
      "Iter 217 time=0.29  loss=26912.39 active=1328  feature_norm=44.91\n",
      "Iter 218 time=0.33  loss=26912.35 active=1328  feature_norm=44.92\n",
      "Iter 219 time=0.28  loss=26911.74 active=1329  feature_norm=44.93\n",
      "Iter 220 time=0.26  loss=26911.69 active=1329  feature_norm=44.93\n",
      "Iter 221 time=0.25  loss=26910.91 active=1327  feature_norm=44.93\n",
      "Iter 222 time=0.54  loss=26910.49 active=1330  feature_norm=44.94\n",
      "Iter 223 time=0.50  loss=26910.28 active=1329  feature_norm=44.94\n",
      "Iter 224 time=0.53  loss=26909.90 active=1332  feature_norm=44.94\n",
      "Iter 225 time=0.51  loss=26909.71 active=1331  feature_norm=44.94\n",
      "Iter 226 time=0.50  loss=26909.30 active=1330  feature_norm=44.95\n",
      "Iter 227 time=0.47  loss=26908.89 active=1332  feature_norm=44.95\n",
      "Iter 228 time=0.48  loss=26908.62 active=1331  feature_norm=44.95\n",
      "Iter 229 time=0.58  loss=26908.13 active=1329  feature_norm=44.96\n",
      "Iter 230 time=0.57  loss=26907.87 active=1326  feature_norm=44.96\n",
      "Iter 231 time=0.59  loss=26907.42 active=1325  feature_norm=44.96\n",
      "Iter 232 time=0.48  loss=26907.15 active=1324  feature_norm=44.96\n",
      "Iter 233 time=0.59  loss=26906.83 active=1322  feature_norm=44.97\n",
      "Iter 234 time=0.59  loss=26906.55 active=1322  feature_norm=44.97\n",
      "Iter 235 time=0.49  loss=26906.18 active=1320  feature_norm=44.97\n",
      "Iter 236 time=0.54  loss=26905.92 active=1318  feature_norm=44.97\n",
      "Iter 237 time=0.43  loss=26905.58 active=1312  feature_norm=44.98\n",
      "Iter 238 time=0.45  loss=26905.31 active=1313  feature_norm=44.98\n",
      "Iter 239 time=0.46  loss=26904.99 active=1311  feature_norm=44.98\n",
      "Iter 240 time=0.43  loss=26904.73 active=1312  feature_norm=44.98\n",
      "Iter 241 time=0.47  loss=26904.45 active=1312  feature_norm=44.99\n",
      "Iter 242 time=0.48  loss=26904.18 active=1311  feature_norm=44.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 243 time=0.45  loss=26903.92 active=1311  feature_norm=44.99\n",
      "Iter 244 time=0.49  loss=26903.62 active=1312  feature_norm=45.00\n",
      "Iter 245 time=0.46  loss=26903.38 active=1312  feature_norm=45.00\n",
      "Iter 246 time=0.46  loss=26903.08 active=1311  feature_norm=45.00\n",
      "Iter 247 time=0.48  loss=26902.85 active=1311  feature_norm=45.01\n",
      "Iter 248 time=0.47  loss=26902.53 active=1312  feature_norm=45.01\n",
      "Iter 249 time=0.46  loss=26902.28 active=1309  feature_norm=45.02\n",
      "Iter 250 time=0.44  loss=26901.99 active=1309  feature_norm=45.02\n",
      "Iter 251 time=0.48  loss=26901.74 active=1308  feature_norm=45.02\n",
      "Iter 252 time=0.44  loss=26901.44 active=1306  feature_norm=45.03\n",
      "Iter 253 time=0.51  loss=26901.21 active=1305  feature_norm=45.03\n",
      "Iter 254 time=0.51  loss=26900.93 active=1306  feature_norm=45.03\n",
      "Iter 255 time=0.48  loss=26900.70 active=1302  feature_norm=45.03\n",
      "Iter 256 time=0.52  loss=26900.41 active=1302  feature_norm=45.03\n",
      "Iter 257 time=0.40  loss=26900.12 active=1300  feature_norm=45.04\n",
      "Iter 258 time=0.44  loss=26899.88 active=1299  feature_norm=45.04\n",
      "Iter 259 time=0.25  loss=26899.85 active=1296  feature_norm=45.05\n",
      "Iter 260 time=0.20  loss=26899.66 active=1297  feature_norm=45.05\n",
      "Iter 261 time=0.21  loss=26898.68 active=1301  feature_norm=45.06\n",
      "Iter 262 time=0.24  loss=26898.22 active=1301  feature_norm=45.06\n",
      "Iter 263 time=0.76  loss=26897.96 active=1299  feature_norm=45.06\n",
      "Iter 264 time=0.44  loss=26897.91 active=1298  feature_norm=45.06\n",
      "Iter 265 time=0.46  loss=26897.64 active=1297  feature_norm=45.06\n",
      "Iter 266 time=0.43  loss=26896.80 active=1301  feature_norm=45.07\n",
      "Iter 267 time=0.49  loss=26896.77 active=1301  feature_norm=45.06\n",
      "Iter 268 time=0.45  loss=26896.19 active=1303  feature_norm=45.07\n",
      "Iter 269 time=0.43  loss=26895.91 active=1304  feature_norm=45.07\n",
      "Iter 270 time=0.20  loss=26895.52 active=1303  feature_norm=45.07\n",
      "Iter 271 time=0.21  loss=26895.45 active=1305  feature_norm=45.06\n",
      "Iter 272 time=0.22  loss=26895.04 active=1305  feature_norm=45.07\n",
      "Iter 273 time=0.27  loss=26894.65 active=1305  feature_norm=45.07\n",
      "Iter 274 time=0.29  loss=26894.07 active=1307  feature_norm=45.07\n",
      "Iter 275 time=0.26  loss=26893.89 active=1305  feature_norm=45.07\n",
      "Iter 276 time=0.23  loss=26893.13 active=1303  feature_norm=45.07\n",
      "Iter 277 time=0.21  loss=26892.89 active=1303  feature_norm=45.07\n",
      "Iter 278 time=0.24  loss=26892.31 active=1302  feature_norm=45.07\n",
      "Iter 279 time=0.27  loss=26892.22 active=1299  feature_norm=45.07\n",
      "Iter 280 time=0.26  loss=26891.48 active=1299  feature_norm=45.08\n",
      "Iter 281 time=0.52  loss=26890.93 active=1299  feature_norm=45.08\n",
      "Iter 282 time=0.23  loss=26890.90 active=1301  feature_norm=45.09\n",
      "Iter 283 time=0.21  loss=26890.70 active=1302  feature_norm=45.09\n",
      "Iter 284 time=0.23  loss=26889.84 active=1302  feature_norm=45.10\n",
      "Iter 285 time=0.46  loss=26889.33 active=1305  feature_norm=45.10\n",
      "Iter 286 time=0.26  loss=26889.03 active=1304  feature_norm=45.11\n",
      "Iter 287 time=0.47  loss=26888.30 active=1303  feature_norm=45.11\n",
      "Iter 288 time=0.74  loss=26888.07 active=1303  feature_norm=45.11"
     ]
    }
   ],
   "source": [
    "crf_tagger.fit(feature_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(sent):\n",
    "    tags = crf_tagger.predict_single(extract_sent_features(list(sent)))\n",
    "    tokens = []\n",
    "    tok = \"\"\n",
    "    for ch, tag in zip(list(sent), tags):\n",
    "        if tag in ['S', 'L'] and tok != \"\":\n",
    "            tokens.append(tok)\n",
    "            tok = \"\"\n",
    "        tok += ch\n",
    "    if tok:\n",
    "        tokens.append(tok)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(actual_toks, pred_toks):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    p = 0\n",
    "    q = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    while i < len(actual_toks) and j < len(pred_toks):\n",
    "        if p == q:\n",
    "            if actual_toks[i] == pred_toks[j]:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "            p += len(actual_toks[i])\n",
    "            q += len(pred_toks[j])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif p < q:\n",
    "            p += len(actual_toks[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "            q += len(pred_toks[j])\n",
    "            j += 1\n",
    "    return tp, fp, len(actual_toks)\n",
    "    \n",
    "def score(actual_sents, pred_sents):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    total = 0\n",
    "    for actual_toks, pred_toks in zip(actual_sents, pred_sents):\n",
    "        tp_, fp_, total_ = compare(actual_toks, pred_toks)\n",
    "        tp += tp_\n",
    "        fp += fp_\n",
    "        total += total_\n",
    "    recall = float(tp) / total\n",
    "    precision = float(tp) / (tp + fp)\n",
    "    f1 = 2.0 * recall * precision / (recall + precision)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afa3bf966b1411f9b36d4910468c7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2023), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "actual = []\n",
    "for sent in tqdm_notebook(raw_test):\n",
    "    pred.append(segment(\"\".join(sent)))\n",
    "    actual.append(sent)\n",
    "\n",
    "recall, precision, f1_score = score(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.9524069358554625\n",
      "Precision:  0.9621878764368402\n",
      "F1 score:  0.9572724225835608\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"F1 score: \", f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
